{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f8368b",
   "metadata": {},
   "source": [
    "## Author : Ibrahim Sobh\n",
    "### Kaggle House Prices - Advanced Regression Technique.\n",
    "- Predict sales prices and practice feature engineering, RFs, and gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc35eb0",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f9904",
   "metadata": {},
   "source": [
    "# I - First Section :  Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7176df6d",
   "metadata": {},
   "source": [
    "## 1 - Importing Libraries & Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a726241",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_log_error,r2_score\n",
    "from sklearn.preprocessing import OrdinalEncoder,StandardScaler\n",
    "\n",
    "# jobLib \n",
    "from joblib import dump,load\n",
    "\n",
    "\n",
    "# Load Data\n",
    "\n",
    "data_master=pd.read_csv('../data/house-prices-advanced-regression-techniques/train.csv')\n",
    "data = data_master.copy()\n",
    "\n",
    "# Carefully Selected Features ( after analysis)\n",
    "list_of_features =[\"OverallQual\",\"GrLivArea\",\"GarageCars\",\"TotalBsmtSF\",\"1stFlrSF\",\n",
    "                  \"FullBath\",\"YearBuilt\",\"YearRemodAdd\",\"BsmtFinSF1\",\"Foundation\",\n",
    "                  \"LotFrontage\",\"WoodDeckSF\",\"MasVnrArea\",\"Fireplaces\",\n",
    "                  \"ExterQual\",\"BsmtQual\",\"KitchenQual\",\"GarageFinish\",\"GarageType\",\"HeatingQC\"]\n",
    "\n",
    "# unwanted Columns \n",
    "unwanted_columns = [\"PoolQC\", \"MiscFeature\",\"Alley\",\"Fence\",\"FireplaceQu\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c6e076",
   "metadata": {},
   "source": [
    "## 2 - Split Data into Train | Test | Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a1177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from typing import Union\n",
    "\n",
    "def data_split_test_train_validation(data: pd.DataFrame, test_size:int =0.2,\n",
    "                                     validation_size:int =0.2) -> pd.DataFrame:\n",
    "    # Split Train / Test\n",
    "    X = data.loc[:, data.columns != 'SalePrice']\n",
    "    y = data.SalePrice\n",
    "    \n",
    "    #First Split L between Train and Test \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        train_size= 1 - test_size,\n",
    "                                                        random_state = 42)\n",
    "    #Second Split :between Train and Validation \n",
    "    X_train, X_validation,y_train, y_validation = train_test_split(X_train, y_train,\n",
    "                                                                   train_size= 1 - validation_size,\n",
    "                                                                   random_state = 42)\n",
    "\n",
    "    # return all splitted data sets ( 6 sets )\n",
    "    return X_train, X_test,X_validation,y_train, y_test,y_validation\n",
    "  \n",
    "X_train, X_test,X_validation,y_train, y_test,y_validation=data_split_test_train_validation(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2e2282",
   "metadata": {},
   "source": [
    "## 3 - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aada6ec",
   "metadata": {},
   "source": [
    "\n",
    "## 3.1 - Preprocessing:  Check up for columns with missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed190af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unwanted_columns(data: pd.DataFrame, columns_list: list=[]) -> pd.DataFrame:\n",
    "    return data.drop(columns_list, axis = 1)\n",
    "\n",
    "# Drop X_train unwanted columns\n",
    "X_train=drop_unwanted_columns(X_train,unwanted_columns)\n",
    "\n",
    "# Drop X_validation unwanted columns\n",
    "X_validation=drop_unwanted_columns(X_validation,unwanted_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c56fd2",
   "metadata": {},
   "source": [
    "## 3.2 - Preprocessing:  Encode Categorical Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63da7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal = OrdinalEncoder(handle_unknown=\"use_encoded_value\",unknown_value=np.nan)\n",
    "\n",
    "def encode_categorical_features(encoder,data: pd.DataFrame,is_test:bool =False) -> pd.DataFrame:\n",
    "    data_categorical = data.select_dtypes(include=['object']).columns\n",
    "    if not is_test :\n",
    "        filename=\"../models/encoder.joblib\" \n",
    "        encoder.fit(data[data_categorical])\n",
    "        dump(ordinal ,filename)\n",
    "    data[data_categorical]=encoder.transform(data[data_categorical])\n",
    "    return data\n",
    "    \n",
    "# X_Train Categories Encoding\n",
    "X_train = encode_categorical_features(ordinal,X_train,False)\n",
    "\n",
    "\n",
    "# X_validation Categories Encoding\n",
    "X_validation = encode_categorical_features(ordinal,X_validation,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f10b99",
   "metadata": {},
   "source": [
    "## 3.3 - Preprocessing:   Fill Features with Null /NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b984ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def fill_features_nulls(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    data_numerical= data.select_dtypes([np.int64,np.float64]).columns\n",
    "    data_categorical = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "    data[data_numerical]=data[data_numerical].fillna(data[data_numerical].mean())\n",
    "    \n",
    "    for feature in data_categorical:\n",
    "        data[feature].interpolate(method ='linear', limit_direction ='forward', inplace=True)\n",
    "        data[feature].interpolate(method ='linear', limit_direction ='backward',inplace=True)\n",
    "        \n",
    "    return data\n",
    "\n",
    "# X_Train Use 'fillna' & interpolate (forward /backward) fill missing values\n",
    "\n",
    "X_train = fill_features_nulls(X_train)\n",
    "\n",
    "# X_validation Use 'fillna' & interpolate (forward /backward) fill missing values\n",
    "\n",
    "X_validation= fill_features_nulls(X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a86479",
   "metadata": {},
   "source": [
    "## 6 -  Scale Data ( Standard Scaler )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbafffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar =StandardScaler()\n",
    "\n",
    "def scale_data(scalar,data: pd.DataFrame,is_test:bool =False) -> pd.DataFrame:\n",
    "    if not is_test:\n",
    "        scalar.fit(data)\n",
    "        filename=\"../models/scalar.joblib\" \n",
    "        dump(scalar ,filename)\n",
    "    return pd.DataFrame(scalar.transform(data),columns = data.columns)\n",
    "\n",
    "# Scale X_train \n",
    "\n",
    "X_train= scale_data(scalar,X_train,False)\n",
    "\n",
    "# Scale X_validation\n",
    "X_validation=scale_data(scalar,X_validation,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8626630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data: pd.DataFrame,to_remove_columns,encoder,scalar) -> pd.DataFrame: \n",
    "    data= drop_unwanted_columns(data,to_remove_columns)\n",
    "    \n",
    "    data= encode_categorical_features(encoder,data,True)\n",
    "    \n",
    "    data= fill_features_nulls(data)\n",
    "    \n",
    "    data= scale_data(scalar,data,True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3363e8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Metrics and Exporting Data\n",
    "\n",
    "def compute_rmsle(y_test: np.ndarray, y_pred: np.ndarray, precision: int = 2) -> float:\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "    return round(rmsle, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e598d",
   "metadata": {},
   "source": [
    "## 7.0 - Model Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511f448",
   "metadata": {},
   "source": [
    "## 7.1- Model Training :  Linear Regression [ First Model ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f591b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set \n",
      "Root-Mean-Squared-Error : 0.164\n",
      "R2 : 0.7931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/model.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_model = LinearRegression()\n",
    "\n",
    "X = X_train[list_of_features]\n",
    "y = y_train\n",
    "\n",
    "LR_model.fit(X, y)\n",
    "y_pred=LR_model.predict(X)\n",
    "\n",
    "y_pred=y_pred.ravel()\n",
    "y_pred =abs(y_pred)\n",
    "y= y.ravel()\n",
    "\n",
    "print(\"Training Set \")\n",
    "print(\"Root-Mean-Squared-Error :\",compute_rmsle(y,y_pred,3))\n",
    "print(\"R2 :\",round(r2_score(y,y_pred),4))\n",
    "filename=\"../models/model.joblib\" \n",
    "dump(LR_model ,filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3585e75d",
   "metadata": {},
   "source": [
    "## 7.2- Model Training :  Model Validation on Validation Set  [ First Model ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50b7dcbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set \n",
      "Root-Mean-Squared-Error : 0.163\n",
      "R2 : 0.8425\n"
     ]
    }
   ],
   "source": [
    "X = X_validation[list_of_features]\n",
    "y = y_validation\n",
    "\n",
    "y_pred=LR_model.predict(X)\n",
    "\n",
    "y_pred=y_pred.ravel()\n",
    "y_pred =abs(y_pred)\n",
    "y= y.ravel()\n",
    "\n",
    "print(\"Validation Set \")\n",
    "print(\"Root-Mean-Squared-Error :\",compute_rmsle(y,y_pred,3))\n",
    "print(\"R2 :\",round(r2_score(y,y_pred),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a94bde8",
   "metadata": {},
   "source": [
    "# II - Second Section :  Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d4eb6",
   "metadata": {},
   "source": [
    "## 1.0 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8352fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test Categories Encoding\n",
    "X_test = drop_unwanted_columns(X_test,unwanted_columns)\n",
    "X_test = encode_categorical_features(ordinal,X_test)\n",
    "X_test = fill_features_nulls(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf0fe1c",
   "metadata": {},
   "source": [
    "## 2 -  Scale Data ( Standard Scaler )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72b013e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= scale_data(scalar,X_test,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae0953d",
   "metadata": {},
   "source": [
    "## 3.0 - Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "653fe6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set \n",
      "Root-Mean-Squared-Error : 0.186\n",
      "R2 : 0.8231\n"
     ]
    }
   ],
   "source": [
    "X = X_test[list_of_features]\n",
    "y = y_test\n",
    "\n",
    "y_pred=LR_model.predict(X)\n",
    "\n",
    "y_pred=y_pred.ravel()\n",
    "y_pred =abs(y_pred)\n",
    "y= y.ravel()\n",
    "\n",
    "print(\"Validation Set \")\n",
    "print(\"Root-Mean-Squared-Error :\",compute_rmsle(y,y_pred,3))\n",
    "print(\"R2 :\",round(r2_score(y,y_pred),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8baccff",
   "metadata": {},
   "source": [
    "# Model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d8c4fb",
   "metadata": {},
   "source": [
    "## Reading File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d7b7d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "test_master=pd.read_csv('../data/house-prices-advanced-regression-techniques/test.csv')\n",
    "test_data = test_master.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3dcf710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f5abc",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7628668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the encoder \n",
    "filename=\"../models/encoder.joblib\" \n",
    "ordinal_loaded =load(filename)\n",
    "\n",
    "# load the scalar\n",
    "filename=\"../models/scalar.joblib\" \n",
    "scalar_loaded=load(filename)\n",
    "\n",
    "# load the model\n",
    "filename=\"../models/model.joblib\" \n",
    "\n",
    "test_data= data_preprocessing(test_data,to_remove_columns=unwanted_columns,\n",
    "                         encoder=ordinal_loaded,scalar=scalar_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047d1b7",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "413f87f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_data[list_of_features]\n",
    "\n",
    "#y_pred=LR_model.predict(X)\n",
    "filename=\"../models/model.joblib\" \n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = load(filename)\n",
    "y_pred= loaded_model.predict(X)\n",
    "\n",
    "test_master[\"SalePrice\"] =y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c95eba43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>103227.754850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>159607.358767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>181746.959687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>196601.597536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>207056.381022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  103227.754850\n",
       "1  1462  159607.358767\n",
       "2  1463  181746.959687\n",
       "3  1464  196601.597536\n",
       "4  1465  207056.381022"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_master[[\"Id\",\"SalePrice\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51799a15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
